/*
 *                         ADLINK Edge SDK
 *
 *   This software and documentation are Copyright 2018 to 2019 ADLINK
 *   Technology Limited, its affiliated companies and licensors. All rights
 *   reserved.
 *
 *   Licensed under the Apache License, Version 2.0 (the "License");
 *   you may not use this file except in compliance with the License.
 *   You may obtain a copy of the License at
 *
 *       http://www.apache.org/licenses/LICENSE-2.0
 *
 *   Unless required by applicable law or agreed to in writing, software
 *   distributed under the License is distributed on an "AS IS" BASIS,
 *   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *   See the License for the specific language governing permissions and
 *   limitations under the License.
 *
 */

/**
 * This code is part of example scenario 1 'Connect a Sensor' of the
 * ADLINK Edge SDK. For a description of this scenario see the
 * 'Edge SDK User Guide' in the /doc directory of the Edge SDK instalation.
 *
 * For instructions on building and running the example see the README
 * file in the Edge SDK installation directory.
 */

#include <opencv2/opencv.hpp>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>
#include <iomanip>
#include <thread>
#include <chrono>
#include <future>
#include <assert.h>
#include <exception>
#include <Dispatcher.hpp>
#include <IoTDataThing.hpp>
#include <JSonThingAPI.hpp>
#include <thing_IoTData.h>
#include <ThingAPIException.hpp>
#include <inference_engine.hpp>
#include "ocv_common.hpp"
#include "slog.hpp"
#include "classification_results.h"

using namespace std;
using namespace com::adlinktech::datariver;
using namespace com::adlinktech::iot;
using namespace InferenceEngine;

#ifdef _MSC_VER
#pragma warning(disable:4996)
#endif

#define READ_SAMPLE_DELAY 100

cv::Mat frame;
cv::Mat mask;

// cv::bitwise_not(mask, mask);
// cv::Mat element = getStructuringElement(cv::MORPH_RECT, cv::Size(20, 20) );
// cv::morphologyEx(mask, mask, cv::MORPH_CLOSE, element); //Does the trick


cv::Ptr<cv::MSER> mser = cv::MSER::create();
vector<vector<cv::Point>> regions;
vector<cv::Rect> boundingBox;
cv::Mat croppedFrame;

InputsDataMap *inputInfo;
OutputsDataMap *outputInfo;
Core core;
const string *inputName;
const string *outputName;
SizeVector inputDims;
SizeVector outputDims;
size_t modelWidth;
size_t modelHeight;
size_t modelChannels;
int channelSize;
int inputSize;
int objectSize;
ExecutableNetwork execNetwork;
InferRequest::Ptr inferRequest;

int loadNetwork(string modelNetwork, string modelWeights, Core plugin, string targetDevice)
{
    // Read IR generated by ModelOptimizer and configure network
    CNNNetReader networkReader;
    networkReader.ReadNetwork(modelNetwork);
    networkReader.ReadWeights(modelWeights);
    CNNNetwork network = networkReader.getNetwork();

    // Get input info
    inputInfo = new InputsDataMap(network.getInputsInfo());
    inputName = &(inputInfo->begin()->first);
    inputDims = inputInfo->begin()->second->getTensorDesc().getDims();

    modelChannels = inputDims[1];
    modelHeight = inputDims[2];
    modelWidth = inputDims[3];

    // Set input info
    (*inputInfo)[*inputName]->getPreProcess().setResizeAlgorithm(RESIZE_AREA);
    (*inputInfo)[*inputName]->setPrecision(Precision::U8);
    (*inputInfo)[*inputName]->setLayout(Layout::NCHW);

    // Get output info
    outputInfo = new OutputsDataMap(network.getOutputsInfo());
    outputName = &(outputInfo->begin()->first);
    outputDims = outputInfo->begin()->second->getDims();

    // Set output info
    (*outputInfo)[*outputName]->setPrecision(Precision::FP32);
    (*outputInfo)[*outputName]->setLayout(Layout::NC);

    // Load model into plugin
    execNetwork = plugin.LoadNetwork(network, targetDevice);

    // Create inference requests
    inferRequest = execNetwork.CreateInferRequestPtr();
    
    return 0;
}

template <typename T>
void cvMatToBlob(const cv::Mat &orig_image, Blob::Ptr &blob, int batchIndex = 0)
{
    SizeVector blobSize = blob.get()->getTensorDesc().getDims();
    const size_t channels = blobSize[1];
    const size_t height = blobSize[2];
    const size_t width = blobSize[3];

    // Get pointer to blob data as type T
    T *blobData = blob->buffer().as<T*>();

    cv::Mat resized_image(orig_image);
    if (static_cast<int>(width) != orig_image.size().width ||
            static_cast<int>(height) != orig_image.size().height) {
        cv::resize(orig_image, resized_image, cv::Size(width, height), 0, 0, cv::INTER_AREA);
    }

    int batchOffset = batchIndex * width * height * channels;

    if(channels == 1)
    {
        for(size_t h = 0; h < height; h++)
        {
            for(size_t w = 0; w < width; w++)
            {
                blobData[batchOffset + h * width + w] = resized_image.at<uchar>(h, w);
            }
        }
    }
    else if(channels == 3)
    {
        for(size_t c = 0; c < channels; c++)
        {
            for(size_t h = 0; h < height; h++)
            {
                for(size_t w = 0; w < width; w++)
                {
                    blobData[batchOffset + c * width * height + h * width + w] = resized_image.at<cv::Vec3b>(h, w)[c];
                }
            }
        }
    }
    else
    {
        THROW_IE_EXCEPTION << "Unsupported number of channels";
    }

    return;
}

void fillInputBlob(cv::Mat img)
{
    Blob::Ptr inputBlob;
    inputBlob = inferRequest->GetBlob(*inputName);

    // cv::Mat resized_image(orig_image);
    // if (static_cast<int>(width) != orig_image.size().width ||
    //         static_cast<int>(height) != orig_image.size().height) {
        // if(img.size != NULL)
        // {
        // cv::resize(orig_image, resized_image, cv::Size(28, 28), 0, 0, cv::INTER_AREA);
        
    // }

    cvMatToBlob<uchar>(img, inputBlob);
    // matU8ToBlob<uint8_t>(img, inputBlob);

    // cout << "Cropped Frame shape: " << resized_image.size << endl;
    // Blob::Ptr imgBlob = wrapMat2Blob(resized_image);

    // inferRequest->SetBlob(*inputName, inputBlob);
        // }
}

void inferenceRequest()
{
    inferRequest->StartAsync();

    // inferRequest->Infer();
}

StatusCode wait()
{
    return inferRequest->Wait(IInferRequest::WaitMode::RESULT_READY);
}

float *inference()
{
    return inferRequest->GetBlob(*outputName)->buffer().as<PrecisionTrait<Precision::FP32>::value_type*>();
}

void boxReduce(vector<cv::Rect> &mserBox)
{
    for(int i = mserBox.size()-1; i >= 0; i--)
    {
        if((mserBox[i].height/mserBox[i].width > 3) ||
            (mserBox[i].width/mserBox[i].height > 3) ||
            (mserBox[i].height < 30) ||
            (mserBox[i].width < 30))
        {
            mserBox.erase(mserBox.begin()+i);
        }
    }

    for(int i = mserBox.size()-1; i >= 1; i--)
    {
        for(int j = i-1; j >= 0; j--)
        {
            if((mserBox[i] & mserBox[j]) == mserBox[i])
            {
                mserBox.erase(mserBox.begin()+i);
            }
            else if((mserBox[j] & mserBox[i]) == mserBox[j])
            {
                mserBox.erase(mserBox.begin()+j);
            }
        }
    }
}

class VideoStreamReceiver {
private:
    string m_thingPropertiesUri;
    DataRiver m_dataRiver = createDataRiver();
    Thing m_thing = createThing();

    DataRiver createDataRiver() {
        return DataRiver::getInstance();
    }

    Thing createThing() {
        // Create and Populate the TagGroup registry with JSON resource files.
        JSonTagGroupRegistry tgr;
        tgr.registerTagGroupsFromURI("file://definitions/TagGroup/com.adlinktech.aati/VideoStreamTagGroup.json");
        m_dataRiver.addTagGroupRegistry(tgr);

        // Create and Populate the ThingClass registry with JSON resource files.
        JSonThingClassRegistry tcr;
        tcr.registerThingClassesFromURI("file://definitions/ThingClass/com.adlinktech.aati/VideoStreamReceiverThingClass.json");
        m_dataRiver.addThingClassRegistry(tcr);

        // Create a Thing based on properties specified in a JSON resource file.
        JSonThingProperties tp;
        tp.readPropertiesFromURI(m_thingPropertiesUri);

        return m_dataRiver.createThing(tp);
    }

    

public:
    VideoStreamReceiver(string thingPropertiesUri) : m_thingPropertiesUri(thingPropertiesUri) {
        cout << "Video Stream Receiver started" << endl;
    }

    ~VideoStreamReceiver() {
        m_dataRiver.close();
        cout << "Video Stream Receiver stopped" << endl;
    }

    int run(int runningTime) {
        long long elapsedSeconds = 0;
        //cv::Mat incomeMat(cv::Size(256, 256), CV_8UC1);

        // network_reader.ReadNetwork("/home/adlink/Desktop/Numbs/model/handwritten.xml");
        // network_reader.ReadWeights("/home/adlink/Desktop/Numbs/model/handwritten.bin");

        // auto network = network_reader.getNetwork();

        // // Taking information about all topology inputs
        // InputsDataMap input_info(network.getInputsInfo());
        // OutputsDataMap output_info(network.getOutputsInfo());

        // cout << "Input infos: " + input_info.size() << endl;
        // cout << "Ouput infos: " + output_info.size() << endl;

        // auto executable_network = core.LoadNetwork(network, "MYRIAD");

        // auto infer_request = executable_network.CreateInferRequest();

        // // Iterating over all input blobs
        // for(auto & item : input_info)
        // {
        //     auto input_name = item.first;
        //     // Getting input blob
        //     auto input = infer_request.GetBlob(input_name);
        // }

        string modelNetwork = "/home/adlink/Desktop/Numbs/model/v3/handwritten_digits_detection_FP32.xml";
        string modelWeights = "/home/adlink/Desktop/Numbs/model/v3/handwritten_digits_detection_FP32.bin";
        string targetDevice = "MYRIAD";

        loadNetwork(modelNetwork, modelWeights, core, targetDevice);

        cout << "Input name: " + *inputName << endl;
        cout << "Input info: " << inputInfo->size() << endl;
        cout << "Input dims: " << inputDims.size() << " [" << inputDims[0] << "," << inputDims[1] << "," << inputDims[2] << "," << inputDims[3] << "]" << endl;

        cout << endl;
        
        cout << "Output name: " + *outputName << endl;
        cout << "Output info: " << outputInfo->size() << endl;
        cout << "Output dims: " << outputDims.size() << " [" << outputDims[0] << "," << outputDims[1] << "]" << endl;

        /** This vector stores id's of top N results **/
        vector<string> resultsID{"0", "1", "2", "3", "4", "5", "6", "7", "8", "9"};
        vector<string> imageNames{"Frame"};

        while(1) {
            // Read all data for input 'temperature'
            vector<DataSample<IOT_NVP_SEQ> > msgs = m_thing.read<IOT_NVP_SEQ>("camera");

            for (const DataSample<IOT_NVP_SEQ>& msg : msgs) {
                auto flowState = msg.getFlowState();
                if (flowState == FlowState::ALIVE) {
                    const IOT_NVP_SEQ& dataSample = msg.getData();
                    try {
                        for (const IOT_NVP& nvp : dataSample) {
                            if (nvp.name() == "camera") {
                                // Buffer = nvp.value().iotv_byte_seq();
                                //incomeMat.data = Buffer;
                                cv::Mat incomeMat(nvp.value().iotv_byte_seq());
                                //cout << incomeMat.total() << endl;
                                frame = incomeMat.reshape(1, 500);
                                // cout << frame.col(0).total() << endl;
                                // cv::resize(incomeMat, frame, cv::Size(720, 720));
                            }

                            cv::threshold(frame, mask, 200, 255, cv::THRESH_BINARY);
                            mser->detectRegions(mask, regions, boundingBox);

                            // for(int i = 0; i < mserBox.size(); i++)
                            // {
                            //     cv::rectangle(frame, mserBox[i], CV_RGB(255, 255, 255));
                            // }
                            // cv::imshow("Video Captured", frame);
                            // cv::imshow("Masked Video Captured", mask);
                            
                            // cout << "Before delete: " << boundingBox.size() << endl;

                            // mserBox.erase(mserBox.begin());
                            // mserBox.erase(mserBox.begin()+1);
                            // mserBox.erase(mserBox.begin()+2);

                            boxReduce(boundingBox);

                            // for(int i = 0; i < mserBox.size(); i++)
                            // {
                            //     if((mserBox[i] & mserBox[i+1]).area() > 0)
                            //     {
                            //         cout << "Found intersected box" << endl;
                            //     }
                            // }

                            // cout << "After delete: " << boundingBox.size() << endl;

                            for(int i = 0; i < boundingBox.size(); i++)
                            {
                                // if(mserBox[i].width < 50 || mserBox[i].height < 50)
                                // {
                                //     continue;
                                // }
                                // top = (int)(0.8*mserBox[i].height);
                                // bottom = top;
                                // right = (int)(0.8*mserBox[i].width);
                                // left = right;
                                
                                cv::Rect myROI(boundingBox[i]);
                                croppedFrame = mask(myROI);
                                cv::copyMakeBorder(croppedFrame, croppedFrame, 50, 50, 50, 50, cv::BORDER_CONSTANT, cv::Scalar(0, 0, 0));
                                // cv::resize(croppedFrame, croppedFrame, cv::Size(28, 28));
                                // cv::imwrite("image" + to_string(i) + ".jpg", croppedFrame);
                                // cv::rectangle(frame, mserBox[i], CV_RGB(255, 255, 255));
                            
                                
                                // cout << "1" << endl;
                                // cv::Mat resizedFrame;
                                // cv::resize(frame, resizedFrame, cv::Size(28, 28));
                                
                                fillInputBlob(croppedFrame);
                                // Blob::Ptr imgBlob = wrapMat2Blob(frame);
                                // inferRequest->SetBlob(*inputName, imgBlob);
                                // cout << "2" << endl;
                                inferenceRequest();
                                // inferRequest->Infer();
                                // cout << "3" << endl;
                                
                                if(wait() == 0)
                                {
                                    Blob::Ptr outputBlob = inferRequest->GetBlob(*outputName);
                                
                                    // ClassificationResult classificationResult(outputBlob, imageNames, 1, 2, resultsID);
                                    // classificationResult.print();
                                    float *result = inference();
                                    // cout << result[0] << "\t"
                                    //     << result[1] << "\t"
                                    //     << result[2] << "\t"
                                    //     << result[3] << "\t"
                                    //     << result[4] << "\t"
                                    //     << result[5] << "\t"
                                    //     << result[6] << "\t"
                                    //     << result[7] << "\t"
                                    //     << result[8] << "\t"
                                    //     << result[9] << endl;
                                    int highestPropIndex = 0;
                                    for(int i = 1; i < 10; i++)
                                    {
                                        // if(result[i] > 0.8)
                                        // {
                                            
                                            // cout << "Detected #: " << resultsID[i] << endl;
                                            // cv::rectangle(frame, cv::Point(0, 440), cv::Point(245, 480), cv::Scalar(0, 0, 0), -1, 8, 0);
                                            // cv::putText(frame, "Detected #: " + resultsID[i], cv::Point(5, 470), cv::FONT_HERSHEY_COMPLEX, 1, cv::Scalar(255, 255, 255), 2);
                                            
                                            
                                        // }
                                        if(result[i] > result[highestPropIndex])
                                        {
                                            highestPropIndex = i;
                                        }
                                        
                                    }
                                    cv::rectangle(frame, boundingBox[i], cv::Scalar(255, 255, 255), 2);
                                    cv::putText(frame, resultsID[highestPropIndex], cv::Point(boundingBox[i].x-30, boundingBox[i].y+10), cv::FONT_HERSHEY_COMPLEX, 1, cv::Scalar(255, 255, 255), 2);
                                }
                            }
                            
                            // if(wait() == 0)
                            // {
                            //     float *results = inference();
                            //     float *result = results + objectSize;
                            //     cout << objectSize << endl;
                            //     // cout << "4" << endl;
                            //     cout << "Prediction:\t" << results[0] << "\t\t"
                            //                             << results[1] << "\t\t"
                            //                             << results[2] << "\t\t"
                            //                             << results[3] << "\t\t"
                            //                             << results[4] << "\t\t"
                            //                             << results[5] << "\t\t"
                            //                             << results[6] << "\t\t"
                            //                             << results[7] << "\t\t"
                            //                             << results[8] << "\t\t" 
                            //                             << results[9] << endl;

                            //     cout.precision(7);
                            //     /** Getting probability for resulting class **/
                            //     const auto result = outputBlob->buffer().
                            //             as<InferenceEngine::PrecisionTrait<InferenceEngine::Precision::FP16>::value_type*>()
                            //     [results[id] + image_id * (_outBlob->size() / _batchSize)];
                            // }
                            cv::imshow("Video Captured", frame);
                            cv::imshow("Masked Video Captured", mask);   
                        }
                    }
                    catch (exception& e) {
                        cerr << "An unexpected error occured while processing data-sample: " << e.what() << endl;
                        continue;
                    }
                }
            }
            if (cv::waitKey(5) == 27)
                break;
        }
        cv::destroyAllWindows();

        return 0;
    }
};

int main(int argc, char *argv[]) {
    // Get thing properties URI from command line parameter
    if (argc < 3) {
        cerr << "Usage: " << argv[0] << " THING_PROPERTIES_URI RUNNING_TIME" << endl;
        exit(1);
    }
    string thingPropertiesUri = string(argv[1]);
    int runningTime = atoi(argv[2]);

    try {
        VideoStreamReceiver(thingPropertiesUri).run(runningTime);
    }
    catch (ThingAPIException& e) {
        cerr << "An unexpected error occurred: " << e.what() << endl;
    }catch(std::exception& e1){
        cerr << "An unexpected error occurred: " << e1.what() << endl;
    }
}
